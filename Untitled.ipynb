{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143\n",
       "2     87\n",
       "1     50\n",
       "3     23\n",
       "Name: cp, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/daniel/.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/daniel/.local/lib/python3.6/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/daniel/.local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/daniel/.local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from networks.NeuralNet import FullyConnectedNet\n",
    "from layers import *\n",
    "import trainer\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(242, 13)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train = train['target']\n",
    "#X_train = train.drop(['target'],  axis =1)\n",
    "#y_test = test['target']\n",
    "#X_test = test.drop(['target'],  axis =1)\n",
    "\n",
    "y = data['target']\n",
    "x = data.drop(['target'],  axis =1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y, test_size = 0.2,random_state = 5)\n",
    "\n",
    "X_train, _, _ = feature_normalize(X_train)\n",
    "X_test, _, _ = feature_normalize(X_test)\n",
    "\n",
    "data = {}\n",
    "data['X_train'] = X_train.as_matrix()\n",
    "data['y_train'] = y_train.values\n",
    "data['y_val'] = y_test.values\n",
    "data['X_val'] = X_test.as_matrix()\n",
    "\n",
    "data['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07030624, -1.50674161, -0.97227182, ..., -0.65683133,\n",
       "        -0.69043052, -0.49747423],\n",
       "       [-1.2729129 , -1.50674161, -0.97227182, ..., -0.65683133,\n",
       "        -0.69043052,  1.15168692],\n",
       "       [-0.15356362,  0.6636838 ,  0.97227182, ...,  0.98186126,\n",
       "         2.31108179, -0.49747423],\n",
       "       ...,\n",
       "       [-0.93710811, -1.50674161,  0.        , ...,  0.98186126,\n",
       "        -0.69043052, -0.49747423],\n",
       "       [-1.49678275,  0.6636838 , -0.97227182, ...,  0.98186126,\n",
       "        -0.69043052,  1.15168692],\n",
       "       [ 0.51804595,  0.6636838 , -0.97227182, ..., -0.65683133,\n",
       "         0.31007359,  1.15168692]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer set to <function adam at 0x7fcfa41d7730>.\n",
      "(Iteration 1 / 12100) loss: 0.693141\n",
      "(Epoch 1 / 5000) train acc: 0.297521; val_acc: 0.360656\n",
      "F1: 0.23529411764705882 \t Precision 0.3 \t recall 0.1935483870967742\n",
      "(Iteration 11 / 12100) loss: 0.359024\n",
      "(Iteration 21 / 12100) loss: 0.288331\n",
      "(Iteration 31 / 12100) loss: 0.277109\n",
      "(Iteration 41 / 12100) loss: 0.295956\n",
      "(Iteration 51 / 12100) loss: 0.211457\n",
      "(Iteration 61 / 12100) loss: 0.188400\n",
      "(Iteration 71 / 12100) loss: 0.221418\n",
      "(Iteration 81 / 12100) loss: 0.214029\n",
      "(Iteration 91 / 12100) loss: 0.222724\n",
      "(Iteration 101 / 12100) loss: 0.218781\n",
      "(Iteration 111 / 12100) loss: 0.216269\n",
      "(Iteration 121 / 12100) loss: 0.174030\n",
      "(Iteration 131 / 12100) loss: 0.125302\n",
      "(Iteration 141 / 12100) loss: 0.160870\n",
      "(Iteration 151 / 12100) loss: 0.181086\n",
      "(Iteration 161 / 12100) loss: 0.123378\n",
      "(Iteration 171 / 12100) loss: 0.159756\n",
      "(Iteration 181 / 12100) loss: 0.147518\n",
      "(Iteration 191 / 12100) loss: 0.144327\n",
      "(Iteration 201 / 12100) loss: 0.197797\n",
      "(Iteration 211 / 12100) loss: 0.125991\n",
      "(Iteration 221 / 12100) loss: 0.134843\n",
      "(Iteration 231 / 12100) loss: 0.173100\n",
      "(Iteration 241 / 12100) loss: 0.069847\n",
      "(Iteration 251 / 12100) loss: 0.103492\n",
      "(Iteration 261 / 12100) loss: 0.136417\n",
      "(Iteration 271 / 12100) loss: 0.162044\n",
      "(Iteration 281 / 12100) loss: 0.090762\n",
      "(Iteration 291 / 12100) loss: 0.037733\n",
      "(Iteration 301 / 12100) loss: 0.136061\n",
      "(Iteration 311 / 12100) loss: 0.107691\n",
      "(Iteration 321 / 12100) loss: 0.055617\n",
      "(Iteration 331 / 12100) loss: 0.088981\n",
      "(Iteration 341 / 12100) loss: 0.160333\n",
      "(Iteration 351 / 12100) loss: 0.091509\n",
      "(Iteration 361 / 12100) loss: 0.088414\n",
      "(Iteration 371 / 12100) loss: 0.060623\n",
      "(Iteration 381 / 12100) loss: 0.067689\n",
      "(Iteration 391 / 12100) loss: 0.037308\n",
      "(Iteration 401 / 12100) loss: 0.064160\n",
      "(Iteration 411 / 12100) loss: 0.077092\n",
      "(Iteration 421 / 12100) loss: 0.073401\n",
      "(Iteration 431 / 12100) loss: 0.041315\n",
      "(Iteration 441 / 12100) loss: 0.065894\n",
      "(Iteration 451 / 12100) loss: 0.067917\n",
      "(Iteration 461 / 12100) loss: 0.036463\n",
      "(Iteration 471 / 12100) loss: 0.031917\n",
      "(Iteration 481 / 12100) loss: 0.043334\n",
      "(Iteration 491 / 12100) loss: 0.080133\n",
      "(Iteration 501 / 12100) loss: 0.088678\n",
      "(Epoch 1 / 5000) train acc: 0.975207; val_acc: 0.836066\n",
      "F1: 0.84375 \t Precision 0.8181818181818182 \t recall 0.8709677419354839\n",
      "(Iteration 511 / 12100) loss: 0.102826\n",
      "(Iteration 521 / 12100) loss: 0.102119\n",
      "(Iteration 531 / 12100) loss: 0.046665\n",
      "(Iteration 541 / 12100) loss: 0.048345\n",
      "(Iteration 551 / 12100) loss: 0.052965\n",
      "(Iteration 561 / 12100) loss: 0.099361\n",
      "(Iteration 571 / 12100) loss: 0.086436\n",
      "(Iteration 581 / 12100) loss: 0.070935\n",
      "(Iteration 591 / 12100) loss: 0.059175\n",
      "(Iteration 601 / 12100) loss: 0.091511\n",
      "(Iteration 611 / 12100) loss: 0.036665\n",
      "(Iteration 621 / 12100) loss: 0.230179\n",
      "(Iteration 631 / 12100) loss: 0.036601\n",
      "(Iteration 641 / 12100) loss: 0.034071\n",
      "(Iteration 651 / 12100) loss: 0.054415\n",
      "(Iteration 661 / 12100) loss: 0.044553\n",
      "(Iteration 671 / 12100) loss: 0.043658\n",
      "(Iteration 681 / 12100) loss: 0.064235\n",
      "(Iteration 691 / 12100) loss: 0.055236\n",
      "(Iteration 701 / 12100) loss: 0.042341\n",
      "(Iteration 711 / 12100) loss: 0.066483\n",
      "(Iteration 721 / 12100) loss: 0.031418\n",
      "(Iteration 731 / 12100) loss: 0.040112\n",
      "(Iteration 741 / 12100) loss: 0.111159\n",
      "(Iteration 751 / 12100) loss: 0.109046\n",
      "(Iteration 761 / 12100) loss: 0.052114\n",
      "(Iteration 771 / 12100) loss: 0.035302\n",
      "(Iteration 781 / 12100) loss: 0.076079\n",
      "(Iteration 791 / 12100) loss: 0.057004\n",
      "(Iteration 801 / 12100) loss: 0.047114\n",
      "(Iteration 811 / 12100) loss: 0.047064\n",
      "(Iteration 821 / 12100) loss: 0.056218\n",
      "(Iteration 831 / 12100) loss: 0.042617\n",
      "(Iteration 841 / 12100) loss: 0.052590\n",
      "(Iteration 851 / 12100) loss: 0.044485\n",
      "(Iteration 861 / 12100) loss: 0.032085\n",
      "(Iteration 871 / 12100) loss: 0.032047\n",
      "(Iteration 881 / 12100) loss: 0.027192\n",
      "(Iteration 891 / 12100) loss: 0.026344\n",
      "(Iteration 901 / 12100) loss: 0.033548\n",
      "(Iteration 911 / 12100) loss: 0.027183\n",
      "(Iteration 921 / 12100) loss: 0.043961\n",
      "(Iteration 931 / 12100) loss: 0.044073\n",
      "(Iteration 941 / 12100) loss: 0.054649\n",
      "(Iteration 951 / 12100) loss: 0.034643\n",
      "(Iteration 961 / 12100) loss: 0.038490\n",
      "(Iteration 971 / 12100) loss: 0.061723\n",
      "(Iteration 981 / 12100) loss: 0.078505\n",
      "(Iteration 991 / 12100) loss: 0.042382\n",
      "(Iteration 1001 / 12100) loss: 0.130242\n",
      "(Epoch 2 / 5000) train acc: 0.983471; val_acc: 0.852459\n",
      "F1: 0.8571428571428571 \t Precision 0.84375 \t recall 0.8709677419354839\n",
      "(Iteration 1011 / 12100) loss: 0.032805\n",
      "(Iteration 1021 / 12100) loss: 0.082984\n",
      "(Iteration 1031 / 12100) loss: 0.056030\n",
      "(Iteration 1041 / 12100) loss: 0.042608\n",
      "(Iteration 1051 / 12100) loss: 0.026230\n",
      "(Iteration 1061 / 12100) loss: 0.029681\n",
      "(Iteration 1071 / 12100) loss: 0.071736\n",
      "(Iteration 1081 / 12100) loss: 0.024915\n",
      "(Iteration 1091 / 12100) loss: 0.048864\n",
      "(Iteration 1101 / 12100) loss: 0.033142\n",
      "(Iteration 1111 / 12100) loss: 0.072653\n",
      "(Iteration 1121 / 12100) loss: 0.029805\n",
      "(Iteration 1131 / 12100) loss: 0.039373\n",
      "(Iteration 1141 / 12100) loss: 0.033836\n",
      "(Iteration 1151 / 12100) loss: 0.035476\n",
      "(Iteration 1161 / 12100) loss: 0.033007\n",
      "(Iteration 1171 / 12100) loss: 0.055430\n",
      "(Iteration 1181 / 12100) loss: 0.032191\n",
      "(Iteration 1191 / 12100) loss: 0.133127\n",
      "(Iteration 1201 / 12100) loss: 0.045651\n",
      "(Iteration 1211 / 12100) loss: 0.081038\n",
      "(Iteration 1221 / 12100) loss: 0.045148\n",
      "(Iteration 1231 / 12100) loss: 0.044208\n",
      "(Iteration 1241 / 12100) loss: 0.034392\n",
      "(Iteration 1251 / 12100) loss: 0.040489\n",
      "(Iteration 1261 / 12100) loss: 0.034989\n",
      "(Iteration 1271 / 12100) loss: 0.053376\n",
      "(Iteration 1281 / 12100) loss: 0.094398\n",
      "(Iteration 1291 / 12100) loss: 0.037335\n",
      "(Iteration 1301 / 12100) loss: 0.047494\n",
      "(Iteration 1311 / 12100) loss: 0.071635\n",
      "(Iteration 1321 / 12100) loss: 0.064465\n",
      "(Iteration 1331 / 12100) loss: 0.052772\n",
      "(Iteration 1341 / 12100) loss: 0.036615\n",
      "(Iteration 1351 / 12100) loss: 0.033883\n",
      "(Iteration 1361 / 12100) loss: 0.025124\n",
      "(Iteration 1371 / 12100) loss: 0.034538\n",
      "(Iteration 1381 / 12100) loss: 0.044591\n",
      "(Iteration 1391 / 12100) loss: 0.046324\n",
      "(Iteration 1401 / 12100) loss: 0.028413\n",
      "(Iteration 1411 / 12100) loss: 0.032090\n",
      "(Iteration 1421 / 12100) loss: 0.056411\n",
      "(Iteration 1431 / 12100) loss: 0.067255\n",
      "(Iteration 1441 / 12100) loss: 0.029624\n",
      "(Iteration 1451 / 12100) loss: 0.068732\n",
      "(Iteration 1461 / 12100) loss: 0.041606\n",
      "(Iteration 1471 / 12100) loss: 0.027842\n",
      "(Iteration 1481 / 12100) loss: 0.051165\n",
      "(Iteration 1491 / 12100) loss: 0.043731\n",
      "(Iteration 1501 / 12100) loss: 0.028651\n",
      "(Epoch 2 / 5000) train acc: 0.995868; val_acc: 0.819672\n",
      "F1: 0.8307692307692308 \t Precision 0.7941176470588235 \t recall 0.8709677419354839\n",
      "(Iteration 1511 / 12100) loss: 0.026431\n",
      "(Iteration 1521 / 12100) loss: 0.165954\n",
      "(Iteration 1531 / 12100) loss: 0.052297\n",
      "(Iteration 1541 / 12100) loss: 0.083494\n",
      "(Iteration 1551 / 12100) loss: 0.035257\n",
      "(Iteration 1561 / 12100) loss: 0.057539\n",
      "(Iteration 1571 / 12100) loss: 0.056860\n",
      "(Iteration 1581 / 12100) loss: 0.049651\n",
      "(Iteration 1591 / 12100) loss: 0.059087\n",
      "(Iteration 1601 / 12100) loss: 0.029935\n",
      "(Iteration 1611 / 12100) loss: 0.035972\n",
      "(Iteration 1621 / 12100) loss: 0.031614\n",
      "(Iteration 1631 / 12100) loss: 0.034297\n",
      "(Iteration 1641 / 12100) loss: 0.026848\n",
      "(Iteration 1651 / 12100) loss: 0.043094\n",
      "(Iteration 1661 / 12100) loss: 0.034399\n",
      "(Iteration 1671 / 12100) loss: 0.035498\n",
      "(Iteration 1681 / 12100) loss: 0.026896\n",
      "(Iteration 1691 / 12100) loss: 0.051864\n",
      "(Iteration 1701 / 12100) loss: 0.032050\n",
      "(Iteration 1711 / 12100) loss: 0.047198\n",
      "(Iteration 1721 / 12100) loss: 0.030288\n",
      "(Iteration 1731 / 12100) loss: 0.032394\n",
      "(Iteration 1741 / 12100) loss: 0.044360\n",
      "(Iteration 1751 / 12100) loss: 0.061237\n",
      "(Iteration 1761 / 12100) loss: 0.032029\n",
      "(Iteration 1771 / 12100) loss: 0.032084\n",
      "(Iteration 1781 / 12100) loss: 0.032583\n",
      "(Iteration 1791 / 12100) loss: 0.048857\n",
      "(Iteration 1801 / 12100) loss: 0.030413\n",
      "(Iteration 1811 / 12100) loss: 0.035292\n",
      "(Iteration 1821 / 12100) loss: 0.031296\n",
      "(Iteration 1831 / 12100) loss: 0.047746\n",
      "(Iteration 1841 / 12100) loss: 0.046493\n",
      "(Iteration 1851 / 12100) loss: 0.042712\n",
      "(Iteration 1861 / 12100) loss: 0.035411\n",
      "(Iteration 1871 / 12100) loss: 0.041000\n",
      "(Iteration 1881 / 12100) loss: 0.062490\n",
      "(Iteration 1891 / 12100) loss: 0.038813\n",
      "(Iteration 1901 / 12100) loss: 0.052930\n",
      "(Iteration 1911 / 12100) loss: 0.037009\n",
      "(Iteration 1921 / 12100) loss: 0.089921\n",
      "(Iteration 1931 / 12100) loss: 0.045893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1941 / 12100) loss: 0.059750\n",
      "(Iteration 1951 / 12100) loss: 0.037364\n",
      "(Iteration 1961 / 12100) loss: 0.039407\n",
      "(Iteration 1971 / 12100) loss: 0.114912\n",
      "(Iteration 1981 / 12100) loss: 0.027811\n",
      "(Iteration 1991 / 12100) loss: 0.030630\n",
      "(Iteration 2001 / 12100) loss: 0.037495\n",
      "(Epoch 3 / 5000) train acc: 0.991736; val_acc: 0.836066\n",
      "F1: 0.84375 \t Precision 0.8181818181818182 \t recall 0.8709677419354839\n",
      "(Iteration 2011 / 12100) loss: 0.039162\n",
      "(Iteration 2021 / 12100) loss: 0.035666\n",
      "(Iteration 2031 / 12100) loss: 0.037544\n",
      "(Iteration 2041 / 12100) loss: 0.030901\n",
      "(Iteration 2051 / 12100) loss: 0.055266\n",
      "(Iteration 2061 / 12100) loss: 0.040868\n",
      "(Iteration 2071 / 12100) loss: 0.031974\n",
      "(Iteration 2081 / 12100) loss: 0.029529\n",
      "(Iteration 2091 / 12100) loss: 0.044105\n",
      "(Iteration 2101 / 12100) loss: 0.038778\n",
      "(Iteration 2111 / 12100) loss: 0.062176\n",
      "(Iteration 2121 / 12100) loss: 0.076572\n",
      "(Iteration 2131 / 12100) loss: 0.044907\n",
      "(Iteration 2141 / 12100) loss: 0.029438\n",
      "(Iteration 2151 / 12100) loss: 0.046344\n",
      "(Iteration 2161 / 12100) loss: 0.027832\n",
      "(Iteration 2171 / 12100) loss: 0.069041\n",
      "(Iteration 2181 / 12100) loss: 0.029312\n",
      "(Iteration 2191 / 12100) loss: 0.028903\n",
      "(Iteration 2201 / 12100) loss: 0.028426\n",
      "(Iteration 2211 / 12100) loss: 0.075420\n",
      "(Iteration 2221 / 12100) loss: 0.040787\n",
      "(Iteration 2231 / 12100) loss: 0.038351\n",
      "(Iteration 2241 / 12100) loss: 0.032892\n",
      "(Iteration 2251 / 12100) loss: 0.034363\n",
      "(Iteration 2261 / 12100) loss: 0.038190\n",
      "(Iteration 2271 / 12100) loss: 0.033890\n",
      "(Iteration 2281 / 12100) loss: 0.038720\n",
      "(Iteration 2291 / 12100) loss: 0.027229\n",
      "(Iteration 2301 / 12100) loss: 0.030518\n",
      "(Iteration 2311 / 12100) loss: 0.065356\n",
      "(Iteration 2321 / 12100) loss: 0.035507\n",
      "(Iteration 2331 / 12100) loss: 0.036834\n",
      "(Iteration 2341 / 12100) loss: 0.036178\n",
      "(Iteration 2351 / 12100) loss: 0.042902\n",
      "(Iteration 2361 / 12100) loss: 0.031878\n",
      "(Iteration 2371 / 12100) loss: 0.044289\n",
      "(Iteration 2381 / 12100) loss: 0.064830\n",
      "(Iteration 2391 / 12100) loss: 0.031926\n",
      "(Iteration 2401 / 12100) loss: 0.064923\n",
      "(Iteration 2411 / 12100) loss: 0.039902\n",
      "(Iteration 2421 / 12100) loss: 0.037618\n",
      "(Iteration 2431 / 12100) loss: 0.038696\n",
      "(Iteration 2441 / 12100) loss: 0.042451\n",
      "(Iteration 2451 / 12100) loss: 0.050729\n",
      "(Iteration 2461 / 12100) loss: 0.030135\n",
      "(Iteration 2471 / 12100) loss: 0.036436\n",
      "(Iteration 2481 / 12100) loss: 0.030974\n",
      "(Iteration 2491 / 12100) loss: 0.033027\n",
      "(Iteration 2501 / 12100) loss: 0.057866\n",
      "(Epoch 3 / 5000) train acc: 0.995868; val_acc: 0.852459\n",
      "F1: 0.8524590163934426 \t Precision 0.8666666666666667 \t recall 0.8387096774193549\n",
      "(Iteration 2511 / 12100) loss: 0.031154\n",
      "(Iteration 2521 / 12100) loss: 0.087581\n",
      "(Iteration 2531 / 12100) loss: 0.032139\n",
      "(Iteration 2541 / 12100) loss: 0.031543\n",
      "(Iteration 2551 / 12100) loss: 0.028984\n",
      "(Iteration 2561 / 12100) loss: 0.028474\n",
      "(Iteration 2571 / 12100) loss: 0.029015\n",
      "(Iteration 2581 / 12100) loss: 0.031914\n",
      "(Iteration 2591 / 12100) loss: 0.063498\n",
      "(Iteration 2601 / 12100) loss: 0.037821\n",
      "(Iteration 2611 / 12100) loss: 0.037128\n",
      "(Iteration 2621 / 12100) loss: 0.031015\n",
      "(Iteration 2631 / 12100) loss: 0.034333\n",
      "(Iteration 2641 / 12100) loss: 0.040902\n",
      "(Iteration 2651 / 12100) loss: 0.036598\n",
      "(Iteration 2661 / 12100) loss: 0.032110\n",
      "(Iteration 2671 / 12100) loss: 0.038114\n",
      "(Iteration 2681 / 12100) loss: 0.037880\n",
      "(Iteration 2691 / 12100) loss: 0.034950\n",
      "(Iteration 2701 / 12100) loss: 0.049932\n",
      "(Iteration 2711 / 12100) loss: 0.027898\n",
      "(Iteration 2721 / 12100) loss: 0.099359\n",
      "(Iteration 2731 / 12100) loss: 0.044032\n",
      "(Iteration 2741 / 12100) loss: 0.094227\n",
      "(Iteration 2751 / 12100) loss: 0.035867\n",
      "(Iteration 2761 / 12100) loss: 0.076262\n",
      "(Iteration 2771 / 12100) loss: 0.094745\n",
      "(Iteration 2781 / 12100) loss: 0.046636\n",
      "(Iteration 2791 / 12100) loss: 0.035001\n",
      "(Iteration 2801 / 12100) loss: 0.032617\n",
      "(Iteration 2811 / 12100) loss: 0.114771\n",
      "(Iteration 2821 / 12100) loss: 0.032537\n",
      "(Iteration 2831 / 12100) loss: 0.032031\n",
      "(Iteration 2841 / 12100) loss: 0.033228\n",
      "(Iteration 2851 / 12100) loss: 0.030757\n",
      "(Iteration 2861 / 12100) loss: 0.048860\n",
      "(Iteration 2871 / 12100) loss: 0.036132\n",
      "(Iteration 2881 / 12100) loss: 0.053934\n",
      "(Iteration 2891 / 12100) loss: 0.032758\n",
      "(Iteration 2901 / 12100) loss: 0.029587\n",
      "(Iteration 2911 / 12100) loss: 0.123454\n",
      "(Iteration 2921 / 12100) loss: 0.039319\n",
      "(Iteration 2931 / 12100) loss: 0.036444\n",
      "(Iteration 2941 / 12100) loss: 0.048973\n",
      "(Iteration 2951 / 12100) loss: 0.037142\n",
      "(Iteration 2961 / 12100) loss: 0.032682\n",
      "(Iteration 2971 / 12100) loss: 0.042048\n",
      "(Iteration 2981 / 12100) loss: 0.029057\n",
      "(Iteration 2991 / 12100) loss: 0.043475\n",
      "(Iteration 3001 / 12100) loss: 0.054978\n",
      "(Epoch 4 / 5000) train acc: 0.987603; val_acc: 0.819672\n",
      "F1: 0.835820895522388 \t Precision 0.7777777777777778 \t recall 0.9032258064516129\n",
      "(Iteration 3011 / 12100) loss: 0.039545\n",
      "(Iteration 3021 / 12100) loss: 0.032821\n",
      "(Iteration 3031 / 12100) loss: 0.052108\n",
      "(Iteration 3041 / 12100) loss: 0.054528\n",
      "(Iteration 3051 / 12100) loss: 0.034638\n",
      "(Iteration 3061 / 12100) loss: 0.130845\n",
      "(Iteration 3071 / 12100) loss: 0.035641\n",
      "(Iteration 3081 / 12100) loss: 0.028817\n",
      "(Iteration 3091 / 12100) loss: 0.032528\n",
      "(Iteration 3101 / 12100) loss: 0.037333\n",
      "(Iteration 3111 / 12100) loss: 0.028588\n",
      "(Iteration 3121 / 12100) loss: 0.028869\n",
      "(Iteration 3131 / 12100) loss: 0.031605\n",
      "(Iteration 3141 / 12100) loss: 0.034293\n",
      "(Iteration 3151 / 12100) loss: 0.035816\n",
      "(Iteration 3161 / 12100) loss: 0.046732\n",
      "(Iteration 3171 / 12100) loss: 0.035177\n",
      "(Iteration 3181 / 12100) loss: 0.030703\n",
      "(Iteration 3191 / 12100) loss: 0.034479\n",
      "(Iteration 3201 / 12100) loss: 0.055313\n",
      "(Iteration 3211 / 12100) loss: 0.036243\n",
      "(Iteration 3221 / 12100) loss: 0.043972\n",
      "(Iteration 3231 / 12100) loss: 0.034560\n",
      "(Iteration 3241 / 12100) loss: 0.035378\n",
      "(Iteration 3251 / 12100) loss: 0.037273\n",
      "(Iteration 3261 / 12100) loss: 0.036283\n",
      "(Iteration 3271 / 12100) loss: 0.067372\n",
      "(Iteration 3281 / 12100) loss: 0.047655\n",
      "(Iteration 3291 / 12100) loss: 0.035743\n",
      "(Iteration 3301 / 12100) loss: 0.033480\n",
      "(Iteration 3311 / 12100) loss: 0.048233\n",
      "(Iteration 3321 / 12100) loss: 0.030177\n",
      "(Iteration 3331 / 12100) loss: 0.032961\n",
      "(Iteration 3341 / 12100) loss: 0.031476\n",
      "(Iteration 3351 / 12100) loss: 0.036944\n",
      "(Iteration 3361 / 12100) loss: 0.046095\n",
      "(Iteration 3371 / 12100) loss: 0.030324\n",
      "(Iteration 3381 / 12100) loss: 0.028927\n",
      "(Iteration 3391 / 12100) loss: 0.034726\n",
      "(Iteration 3401 / 12100) loss: 0.032188\n",
      "(Iteration 3411 / 12100) loss: 0.043423\n",
      "(Iteration 3421 / 12100) loss: 0.030107\n",
      "(Iteration 3431 / 12100) loss: 0.033215\n",
      "(Iteration 3441 / 12100) loss: 0.095783\n",
      "(Iteration 3451 / 12100) loss: 0.043107\n",
      "(Iteration 3461 / 12100) loss: 0.029736\n",
      "(Iteration 3471 / 12100) loss: 0.030697\n",
      "(Iteration 3481 / 12100) loss: 0.053160\n",
      "(Iteration 3491 / 12100) loss: 0.033138\n",
      "(Iteration 3501 / 12100) loss: 0.031278\n",
      "(Epoch 4 / 5000) train acc: 0.987603; val_acc: 0.852459\n",
      "F1: 0.8615384615384616 \t Precision 0.8235294117647058 \t recall 0.9032258064516129\n",
      "(Iteration 3511 / 12100) loss: 0.030040\n",
      "(Iteration 3521 / 12100) loss: 0.050595\n",
      "(Iteration 3531 / 12100) loss: 0.071864\n",
      "(Iteration 3541 / 12100) loss: 0.031656\n",
      "(Iteration 3551 / 12100) loss: 0.031152\n",
      "(Iteration 3561 / 12100) loss: 0.071790\n",
      "(Iteration 3571 / 12100) loss: 0.032860\n",
      "(Iteration 3581 / 12100) loss: 0.031045\n",
      "(Iteration 3591 / 12100) loss: 0.052807\n",
      "(Iteration 3601 / 12100) loss: 0.030086\n",
      "(Iteration 3611 / 12100) loss: 0.033973\n",
      "(Iteration 3621 / 12100) loss: 0.037324\n",
      "(Iteration 3631 / 12100) loss: 0.031377\n",
      "(Iteration 3641 / 12100) loss: 0.045549\n",
      "(Iteration 3651 / 12100) loss: 0.039521\n",
      "(Iteration 3661 / 12100) loss: 0.036732\n",
      "(Iteration 3671 / 12100) loss: 0.033165\n",
      "(Iteration 3681 / 12100) loss: 0.041831\n",
      "(Iteration 3691 / 12100) loss: 0.048592\n",
      "(Iteration 3701 / 12100) loss: 0.029993\n",
      "(Iteration 3711 / 12100) loss: 0.071364\n",
      "(Iteration 3721 / 12100) loss: 0.029666\n",
      "(Iteration 3731 / 12100) loss: 0.030770\n",
      "(Iteration 3741 / 12100) loss: 0.033130\n",
      "(Iteration 3751 / 12100) loss: 0.054128\n",
      "(Iteration 3761 / 12100) loss: 0.099336\n",
      "(Iteration 3771 / 12100) loss: 0.040876\n",
      "(Iteration 3781 / 12100) loss: 0.033984\n",
      "(Iteration 3791 / 12100) loss: 0.051289\n",
      "(Iteration 3801 / 12100) loss: 0.029401\n",
      "(Iteration 3811 / 12100) loss: 0.032187\n",
      "(Iteration 3821 / 12100) loss: 0.034354\n",
      "(Iteration 3831 / 12100) loss: 0.032562\n",
      "(Iteration 3841 / 12100) loss: 0.049924\n",
      "(Iteration 3851 / 12100) loss: 0.040266\n",
      "(Iteration 3861 / 12100) loss: 0.037171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 3871 / 12100) loss: 0.029328\n",
      "(Iteration 3881 / 12100) loss: 0.036171\n",
      "(Iteration 3891 / 12100) loss: 0.067927\n",
      "(Iteration 3901 / 12100) loss: 0.030996\n",
      "(Iteration 3911 / 12100) loss: 0.037662\n",
      "(Iteration 3921 / 12100) loss: 0.085661\n",
      "(Iteration 3931 / 12100) loss: 0.029107\n",
      "(Iteration 3941 / 12100) loss: 0.043574\n",
      "(Iteration 3951 / 12100) loss: 0.035999\n",
      "(Iteration 3961 / 12100) loss: 0.030885\n",
      "(Iteration 3971 / 12100) loss: 0.038607\n",
      "(Iteration 3981 / 12100) loss: 0.028407\n",
      "(Iteration 3991 / 12100) loss: 0.030674\n",
      "(Iteration 4001 / 12100) loss: 0.029247\n",
      "(Epoch 5 / 5000) train acc: 0.971074; val_acc: 0.868852\n",
      "F1: 0.8787878787878788 \t Precision 0.8285714285714286 \t recall 0.9354838709677419\n",
      "(Iteration 4011 / 12100) loss: 0.036487\n",
      "(Iteration 4021 / 12100) loss: 0.033937\n",
      "(Iteration 4031 / 12100) loss: 0.035229\n",
      "(Iteration 4041 / 12100) loss: 0.039541\n",
      "(Iteration 4051 / 12100) loss: 0.036783\n",
      "(Iteration 4061 / 12100) loss: 0.035249\n",
      "(Iteration 4071 / 12100) loss: 0.049975\n",
      "(Iteration 4081 / 12100) loss: 0.046273\n",
      "(Iteration 4091 / 12100) loss: 0.029954\n",
      "(Iteration 4101 / 12100) loss: 0.034978\n",
      "(Iteration 4111 / 12100) loss: 0.038209\n",
      "(Iteration 4121 / 12100) loss: 0.040169\n",
      "(Iteration 4131 / 12100) loss: 0.030134\n",
      "(Iteration 4141 / 12100) loss: 0.105346\n",
      "(Iteration 4151 / 12100) loss: 0.061140\n",
      "(Iteration 4161 / 12100) loss: 0.035019\n",
      "(Iteration 4171 / 12100) loss: 0.047409\n",
      "(Iteration 4181 / 12100) loss: 0.035620\n",
      "(Iteration 4191 / 12100) loss: 0.031623\n",
      "(Iteration 4201 / 12100) loss: 0.033009\n",
      "(Iteration 4211 / 12100) loss: 0.033134\n",
      "(Iteration 4221 / 12100) loss: 0.032177\n",
      "(Iteration 4231 / 12100) loss: 0.066397\n",
      "(Iteration 4241 / 12100) loss: 0.060670\n",
      "(Iteration 4251 / 12100) loss: 0.041453\n",
      "(Iteration 4261 / 12100) loss: 0.032571\n",
      "(Iteration 4271 / 12100) loss: 0.045538\n",
      "(Iteration 4281 / 12100) loss: 0.060721\n",
      "(Iteration 4291 / 12100) loss: 0.036293\n",
      "(Iteration 4301 / 12100) loss: 0.033799\n",
      "(Iteration 4311 / 12100) loss: 0.031780\n",
      "(Iteration 4321 / 12100) loss: 0.041771\n",
      "(Iteration 4331 / 12100) loss: 0.035885\n",
      "(Iteration 4341 / 12100) loss: 0.043465\n",
      "(Iteration 4351 / 12100) loss: 0.030208\n",
      "(Iteration 4361 / 12100) loss: 0.030626\n",
      "(Iteration 4371 / 12100) loss: 0.069168\n",
      "(Iteration 4381 / 12100) loss: 0.045038\n",
      "(Iteration 4391 / 12100) loss: 0.036109\n",
      "(Iteration 4401 / 12100) loss: 0.035714\n",
      "(Iteration 4411 / 12100) loss: 0.036475\n",
      "(Iteration 4421 / 12100) loss: 0.032347\n",
      "(Iteration 4431 / 12100) loss: 0.037179\n",
      "(Iteration 4441 / 12100) loss: 0.032265\n",
      "(Iteration 4451 / 12100) loss: 0.031692\n",
      "(Iteration 4461 / 12100) loss: 0.030478\n",
      "(Iteration 4471 / 12100) loss: 0.052435\n",
      "(Iteration 4481 / 12100) loss: 0.034485\n",
      "(Iteration 4491 / 12100) loss: 0.037572\n",
      "(Iteration 4501 / 12100) loss: 0.047997\n",
      "(Epoch 5 / 5000) train acc: 0.987603; val_acc: 0.901639\n",
      "F1: 0.90625 \t Precision 0.8787878787878788 \t recall 0.9354838709677419\n",
      "(Iteration 4511 / 12100) loss: 0.046021\n",
      "(Iteration 4521 / 12100) loss: 0.056351\n",
      "(Iteration 4531 / 12100) loss: 0.031390\n",
      "(Iteration 4541 / 12100) loss: 0.049546\n",
      "(Iteration 4551 / 12100) loss: 0.029485\n",
      "(Iteration 4561 / 12100) loss: 0.041859\n",
      "(Iteration 4571 / 12100) loss: 0.029465\n",
      "(Iteration 4581 / 12100) loss: 0.030049\n",
      "(Iteration 4591 / 12100) loss: 0.036550\n",
      "(Iteration 4601 / 12100) loss: 0.029115\n",
      "(Iteration 4611 / 12100) loss: 0.055671\n",
      "(Iteration 4621 / 12100) loss: 0.030654\n",
      "(Iteration 4631 / 12100) loss: 0.033151\n",
      "(Iteration 4641 / 12100) loss: 0.056608\n",
      "(Iteration 4651 / 12100) loss: 0.056584\n",
      "(Iteration 4661 / 12100) loss: 0.042542\n",
      "(Iteration 4671 / 12100) loss: 0.037685\n",
      "(Iteration 4681 / 12100) loss: 0.041181\n",
      "(Iteration 4691 / 12100) loss: 0.031900\n",
      "(Iteration 4701 / 12100) loss: 0.030682\n",
      "(Iteration 4711 / 12100) loss: 0.031128\n",
      "(Iteration 4721 / 12100) loss: 0.037261\n",
      "(Iteration 4731 / 12100) loss: 0.034186\n",
      "(Iteration 4741 / 12100) loss: 0.034443\n",
      "(Iteration 4751 / 12100) loss: 0.042319\n",
      "(Iteration 4761 / 12100) loss: 0.045850\n",
      "(Iteration 4771 / 12100) loss: 0.041118\n",
      "(Iteration 4781 / 12100) loss: 0.038597\n",
      "(Iteration 4791 / 12100) loss: 0.039529\n",
      "(Iteration 4801 / 12100) loss: 0.046456\n",
      "(Iteration 4811 / 12100) loss: 0.047498\n",
      "(Iteration 4821 / 12100) loss: 0.033230\n",
      "(Iteration 4831 / 12100) loss: 0.033954\n",
      "(Iteration 4841 / 12100) loss: 0.046564\n",
      "(Iteration 4851 / 12100) loss: 0.040818\n",
      "(Iteration 4861 / 12100) loss: 0.032149\n",
      "(Iteration 4871 / 12100) loss: 0.030320\n",
      "(Iteration 4881 / 12100) loss: 0.033784\n",
      "(Iteration 4891 / 12100) loss: 0.031283\n",
      "(Iteration 4901 / 12100) loss: 0.035085\n",
      "(Iteration 4911 / 12100) loss: 0.033074\n",
      "(Iteration 4921 / 12100) loss: 0.033769\n",
      "(Iteration 4931 / 12100) loss: 0.040386\n",
      "(Iteration 4941 / 12100) loss: 0.051588\n",
      "(Iteration 4951 / 12100) loss: 0.039904\n",
      "(Iteration 4961 / 12100) loss: 0.039494\n",
      "(Iteration 4971 / 12100) loss: 0.033138\n",
      "(Iteration 4981 / 12100) loss: 0.045039\n",
      "(Iteration 4991 / 12100) loss: 0.035318\n",
      "(Iteration 5001 / 12100) loss: 0.047702\n",
      "(Epoch 6 / 5000) train acc: 0.979339; val_acc: 0.852459\n",
      "F1: 0.8571428571428571 \t Precision 0.84375 \t recall 0.8709677419354839\n",
      "(Iteration 5011 / 12100) loss: 0.117671\n",
      "(Iteration 5021 / 12100) loss: 0.044460\n",
      "(Iteration 5031 / 12100) loss: 0.032976\n",
      "(Iteration 5041 / 12100) loss: 0.057685\n",
      "(Iteration 5051 / 12100) loss: 0.038614\n",
      "(Iteration 5061 / 12100) loss: 0.058181\n",
      "(Iteration 5071 / 12100) loss: 0.038945\n",
      "(Iteration 5081 / 12100) loss: 0.035818\n",
      "(Iteration 5091 / 12100) loss: 0.051777\n",
      "(Iteration 5101 / 12100) loss: 0.033945\n",
      "(Iteration 5111 / 12100) loss: 0.033431\n",
      "(Iteration 5121 / 12100) loss: 0.033951\n",
      "(Iteration 5131 / 12100) loss: 0.039954\n",
      "(Iteration 5141 / 12100) loss: 0.035343\n",
      "(Iteration 5151 / 12100) loss: 0.044396\n",
      "(Iteration 5161 / 12100) loss: 0.030260\n",
      "(Iteration 5171 / 12100) loss: 0.032905\n",
      "(Iteration 5181 / 12100) loss: 0.031731\n",
      "(Iteration 5191 / 12100) loss: 0.033183\n",
      "(Iteration 5201 / 12100) loss: 0.037982\n",
      "(Iteration 5211 / 12100) loss: 0.029775\n",
      "(Iteration 5221 / 12100) loss: 0.039593\n",
      "(Iteration 5231 / 12100) loss: 0.029840\n",
      "(Iteration 5241 / 12100) loss: 0.032293\n",
      "(Iteration 5251 / 12100) loss: 0.029024\n",
      "(Iteration 5261 / 12100) loss: 0.073172\n",
      "(Iteration 5271 / 12100) loss: 0.055817\n",
      "(Iteration 5281 / 12100) loss: 0.094133\n",
      "(Iteration 5291 / 12100) loss: 0.029884\n",
      "(Iteration 5301 / 12100) loss: 0.097445\n",
      "(Iteration 5311 / 12100) loss: 0.036892\n",
      "(Iteration 5321 / 12100) loss: 0.032596\n",
      "(Iteration 5331 / 12100) loss: 0.041931\n",
      "(Iteration 5341 / 12100) loss: 0.038307\n",
      "(Iteration 5351 / 12100) loss: 0.062605\n",
      "(Iteration 5361 / 12100) loss: 0.028986\n",
      "(Iteration 5371 / 12100) loss: 0.052511\n",
      "(Iteration 5381 / 12100) loss: 0.055655\n",
      "(Iteration 5391 / 12100) loss: 0.033211\n",
      "(Iteration 5401 / 12100) loss: 0.030245\n",
      "(Iteration 5411 / 12100) loss: 0.045094\n",
      "(Iteration 5421 / 12100) loss: 0.036487\n",
      "(Iteration 5431 / 12100) loss: 0.072864\n",
      "(Iteration 5441 / 12100) loss: 0.047363\n",
      "(Iteration 5451 / 12100) loss: 0.042057\n",
      "(Iteration 5461 / 12100) loss: 0.030174\n",
      "(Iteration 5471 / 12100) loss: 0.036212\n",
      "(Iteration 5481 / 12100) loss: 0.033266\n",
      "(Iteration 5491 / 12100) loss: 0.065950\n",
      "(Iteration 5501 / 12100) loss: 0.040858\n",
      "(Epoch 6 / 5000) train acc: 0.971074; val_acc: 0.868852\n",
      "F1: 0.8709677419354839 \t Precision 0.8709677419354839 \t recall 0.8709677419354839\n",
      "(Iteration 5511 / 12100) loss: 0.042373\n",
      "(Iteration 5521 / 12100) loss: 0.081259\n",
      "(Iteration 5531 / 12100) loss: 0.036921\n",
      "(Iteration 5541 / 12100) loss: 0.049620\n",
      "(Iteration 5551 / 12100) loss: 0.032440\n",
      "(Iteration 5561 / 12100) loss: 0.042432\n",
      "(Iteration 5571 / 12100) loss: 0.034909\n",
      "(Iteration 5581 / 12100) loss: 0.033279\n",
      "(Iteration 5591 / 12100) loss: 0.039967\n",
      "(Iteration 5601 / 12100) loss: 0.031939\n",
      "(Iteration 5611 / 12100) loss: 0.035833\n",
      "(Iteration 5621 / 12100) loss: 0.067391\n",
      "(Iteration 5631 / 12100) loss: 0.031936\n",
      "(Iteration 5641 / 12100) loss: 0.043439\n",
      "(Iteration 5651 / 12100) loss: 0.051291\n",
      "(Iteration 5661 / 12100) loss: 0.030916\n",
      "(Iteration 5671 / 12100) loss: 0.032641\n",
      "(Iteration 5681 / 12100) loss: 0.029813\n",
      "(Iteration 5691 / 12100) loss: 0.046232\n",
      "(Iteration 5701 / 12100) loss: 0.039223\n",
      "(Iteration 5711 / 12100) loss: 0.031890\n",
      "(Iteration 5721 / 12100) loss: 0.032902\n",
      "(Iteration 5731 / 12100) loss: 0.040731\n",
      "(Iteration 5741 / 12100) loss: 0.041073\n",
      "(Iteration 5751 / 12100) loss: 0.031135\n",
      "(Iteration 5761 / 12100) loss: 0.071910\n",
      "(Iteration 5771 / 12100) loss: 0.078771\n",
      "(Iteration 5781 / 12100) loss: 0.029494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 5791 / 12100) loss: 0.044208\n",
      "(Iteration 5801 / 12100) loss: 0.061463\n",
      "(Iteration 5811 / 12100) loss: 0.033298\n",
      "(Iteration 5821 / 12100) loss: 0.029663\n",
      "(Iteration 5831 / 12100) loss: 0.036033\n",
      "(Iteration 5841 / 12100) loss: 0.035482\n",
      "(Iteration 5851 / 12100) loss: 0.029306\n",
      "(Iteration 5861 / 12100) loss: 0.076212\n",
      "(Iteration 5871 / 12100) loss: 0.034448\n",
      "(Iteration 5881 / 12100) loss: 0.032367\n",
      "(Iteration 5891 / 12100) loss: 0.049598\n",
      "(Iteration 5901 / 12100) loss: 0.031096\n",
      "(Iteration 5911 / 12100) loss: 0.030251\n",
      "(Iteration 5921 / 12100) loss: 0.031424\n",
      "(Iteration 5931 / 12100) loss: 0.040649\n",
      "(Iteration 5941 / 12100) loss: 0.054138\n",
      "(Iteration 5951 / 12100) loss: 0.041685\n",
      "(Iteration 5961 / 12100) loss: 0.045449\n",
      "(Iteration 5971 / 12100) loss: 0.036049\n",
      "(Iteration 5981 / 12100) loss: 0.031599\n",
      "(Iteration 5991 / 12100) loss: 0.046352\n",
      "(Iteration 6001 / 12100) loss: 0.078766\n",
      "(Epoch 7 / 5000) train acc: 0.971074; val_acc: 0.836066\n",
      "F1: 0.84375 \t Precision 0.8181818181818182 \t recall 0.8709677419354839\n",
      "(Iteration 6011 / 12100) loss: 0.047034\n",
      "(Iteration 6021 / 12100) loss: 0.038980\n",
      "(Iteration 6031 / 12100) loss: 0.037736\n",
      "(Iteration 6041 / 12100) loss: 0.036624\n",
      "(Iteration 6051 / 12100) loss: 0.030100\n",
      "(Iteration 6061 / 12100) loss: 0.030930\n",
      "(Iteration 6071 / 12100) loss: 0.030126\n",
      "(Iteration 6081 / 12100) loss: 0.030710\n",
      "(Iteration 6091 / 12100) loss: 0.031602\n",
      "(Iteration 6101 / 12100) loss: 0.034537\n",
      "(Iteration 6111 / 12100) loss: 0.029753\n",
      "(Iteration 6121 / 12100) loss: 0.043752\n",
      "(Iteration 6131 / 12100) loss: 0.028805\n",
      "(Iteration 6141 / 12100) loss: 0.030751\n",
      "(Iteration 6151 / 12100) loss: 0.034674\n",
      "(Iteration 6161 / 12100) loss: 0.030599\n",
      "(Iteration 6171 / 12100) loss: 0.031667\n",
      "(Iteration 6181 / 12100) loss: 0.029565\n",
      "(Iteration 6191 / 12100) loss: 0.029555\n",
      "(Iteration 6201 / 12100) loss: 0.064462\n",
      "(Iteration 6211 / 12100) loss: 0.040737\n",
      "(Iteration 6221 / 12100) loss: 0.048949\n",
      "(Iteration 6231 / 12100) loss: 0.031896\n",
      "(Iteration 6241 / 12100) loss: 0.031814\n",
      "(Iteration 6251 / 12100) loss: 0.044516\n",
      "(Iteration 6261 / 12100) loss: 0.037047\n",
      "(Iteration 6271 / 12100) loss: 0.030992\n",
      "(Iteration 6281 / 12100) loss: 0.037006\n",
      "(Iteration 6291 / 12100) loss: 0.034677\n",
      "(Iteration 6301 / 12100) loss: 0.029724\n",
      "(Iteration 6311 / 12100) loss: 0.037004\n",
      "(Iteration 6321 / 12100) loss: 0.039780\n",
      "(Iteration 6331 / 12100) loss: 0.029262\n",
      "(Iteration 6341 / 12100) loss: 0.031840\n",
      "(Iteration 6351 / 12100) loss: 0.032667\n",
      "(Iteration 6361 / 12100) loss: 0.041610\n",
      "(Iteration 6371 / 12100) loss: 0.029878\n",
      "(Iteration 6381 / 12100) loss: 0.029043\n",
      "(Iteration 6391 / 12100) loss: 0.031126\n",
      "(Iteration 6401 / 12100) loss: 0.080900\n",
      "(Iteration 6411 / 12100) loss: 0.055008\n",
      "(Iteration 6421 / 12100) loss: 0.089671\n",
      "(Iteration 6431 / 12100) loss: 0.037335\n",
      "(Iteration 6441 / 12100) loss: 0.045990\n",
      "(Iteration 6451 / 12100) loss: 0.043632\n",
      "(Iteration 6461 / 12100) loss: 0.034313\n",
      "(Iteration 6471 / 12100) loss: 0.035552\n",
      "(Iteration 6481 / 12100) loss: 0.070550\n",
      "(Iteration 6491 / 12100) loss: 0.061586\n",
      "(Iteration 6501 / 12100) loss: 0.032110\n",
      "(Epoch 7 / 5000) train acc: 0.966942; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 6511 / 12100) loss: 0.040966\n",
      "(Iteration 6521 / 12100) loss: 0.032173\n",
      "(Iteration 6531 / 12100) loss: 0.053353\n",
      "(Iteration 6541 / 12100) loss: 0.032575\n",
      "(Iteration 6551 / 12100) loss: 0.035788\n",
      "(Iteration 6561 / 12100) loss: 0.032483\n",
      "(Iteration 6571 / 12100) loss: 0.029650\n",
      "(Iteration 6581 / 12100) loss: 0.055815\n",
      "(Iteration 6591 / 12100) loss: 0.033872\n",
      "(Iteration 6601 / 12100) loss: 0.032104\n",
      "(Iteration 6611 / 12100) loss: 0.029868\n",
      "(Iteration 6621 / 12100) loss: 0.051561\n",
      "(Iteration 6631 / 12100) loss: 0.029668\n",
      "(Iteration 6641 / 12100) loss: 0.033954\n",
      "(Iteration 6651 / 12100) loss: 0.038703\n",
      "(Iteration 6661 / 12100) loss: 0.048473\n",
      "(Iteration 6671 / 12100) loss: 0.085192\n",
      "(Iteration 6681 / 12100) loss: 0.031863\n",
      "(Iteration 6691 / 12100) loss: 0.031051\n",
      "(Iteration 6701 / 12100) loss: 0.032255\n",
      "(Iteration 6711 / 12100) loss: 0.030948\n",
      "(Iteration 6721 / 12100) loss: 0.032628\n",
      "(Iteration 6731 / 12100) loss: 0.032934\n",
      "(Iteration 6741 / 12100) loss: 0.099679\n",
      "(Iteration 6751 / 12100) loss: 0.131478\n",
      "(Iteration 6761 / 12100) loss: 0.061492\n",
      "(Iteration 6771 / 12100) loss: 0.032919\n",
      "(Iteration 6781 / 12100) loss: 0.031816\n",
      "(Iteration 6791 / 12100) loss: 0.033601\n",
      "(Iteration 6801 / 12100) loss: 0.053599\n",
      "(Iteration 6811 / 12100) loss: 0.032725\n",
      "(Iteration 6821 / 12100) loss: 0.037111\n",
      "(Iteration 6831 / 12100) loss: 0.048669\n",
      "(Iteration 6841 / 12100) loss: 0.061930\n",
      "(Iteration 6851 / 12100) loss: 0.032015\n",
      "(Iteration 6861 / 12100) loss: 0.032757\n",
      "(Iteration 6871 / 12100) loss: 0.032719\n",
      "(Iteration 6881 / 12100) loss: 0.051166\n",
      "(Iteration 6891 / 12100) loss: 0.040318\n",
      "(Iteration 6901 / 12100) loss: 0.033237\n",
      "(Iteration 6911 / 12100) loss: 0.050351\n",
      "(Iteration 6921 / 12100) loss: 0.037464\n",
      "(Iteration 6931 / 12100) loss: 0.031627\n",
      "(Iteration 6941 / 12100) loss: 0.033670\n",
      "(Iteration 6951 / 12100) loss: 0.032085\n",
      "(Iteration 6961 / 12100) loss: 0.049587\n",
      "(Iteration 6971 / 12100) loss: 0.031924\n",
      "(Iteration 6981 / 12100) loss: 0.054620\n",
      "(Iteration 6991 / 12100) loss: 0.039157\n",
      "(Iteration 7001 / 12100) loss: 0.065510\n",
      "(Epoch 8 / 5000) train acc: 0.946281; val_acc: 0.868852\n",
      "F1: 0.8787878787878788 \t Precision 0.8285714285714286 \t recall 0.9354838709677419\n",
      "(Iteration 7011 / 12100) loss: 0.031578\n",
      "(Iteration 7021 / 12100) loss: 0.033962\n",
      "(Iteration 7031 / 12100) loss: 0.043117\n",
      "(Iteration 7041 / 12100) loss: 0.035107\n",
      "(Iteration 7051 / 12100) loss: 0.035431\n",
      "(Iteration 7061 / 12100) loss: 0.034269\n",
      "(Iteration 7071 / 12100) loss: 0.035894\n",
      "(Iteration 7081 / 12100) loss: 0.033896\n",
      "(Iteration 7091 / 12100) loss: 0.030585\n",
      "(Iteration 7101 / 12100) loss: 0.034581\n",
      "(Iteration 7111 / 12100) loss: 0.029674\n",
      "(Iteration 7121 / 12100) loss: 0.031167\n",
      "(Iteration 7131 / 12100) loss: 0.030529\n",
      "(Iteration 7141 / 12100) loss: 0.029844\n",
      "(Iteration 7151 / 12100) loss: 0.030876\n",
      "(Iteration 7161 / 12100) loss: 0.038527\n",
      "(Iteration 7171 / 12100) loss: 0.033055\n",
      "(Iteration 7181 / 12100) loss: 0.044505\n",
      "(Iteration 7191 / 12100) loss: 0.040409\n",
      "(Iteration 7201 / 12100) loss: 0.031346\n",
      "(Iteration 7211 / 12100) loss: 0.029666\n",
      "(Iteration 7221 / 12100) loss: 0.034119\n",
      "(Iteration 7231 / 12100) loss: 0.030605\n",
      "(Iteration 7241 / 12100) loss: 0.057942\n",
      "(Iteration 7251 / 12100) loss: 0.043658\n",
      "(Iteration 7261 / 12100) loss: 0.040260\n",
      "(Iteration 7271 / 12100) loss: 0.035502\n",
      "(Iteration 7281 / 12100) loss: 0.034558\n",
      "(Iteration 7291 / 12100) loss: 0.034606\n",
      "(Iteration 7301 / 12100) loss: 0.038698\n",
      "(Iteration 7311 / 12100) loss: 0.050277\n",
      "(Iteration 7321 / 12100) loss: 0.052984\n",
      "(Iteration 7331 / 12100) loss: 0.031180\n",
      "(Iteration 7341 / 12100) loss: 0.034310\n",
      "(Iteration 7351 / 12100) loss: 0.038105\n",
      "(Iteration 7361 / 12100) loss: 0.030641\n",
      "(Iteration 7371 / 12100) loss: 0.033531\n",
      "(Iteration 7381 / 12100) loss: 0.032111\n",
      "(Iteration 7391 / 12100) loss: 0.033915\n",
      "(Iteration 7401 / 12100) loss: 0.031973\n",
      "(Iteration 7411 / 12100) loss: 0.044877\n",
      "(Iteration 7421 / 12100) loss: 0.041415\n",
      "(Iteration 7431 / 12100) loss: 0.029523\n",
      "(Iteration 7441 / 12100) loss: 0.062878\n",
      "(Iteration 7451 / 12100) loss: 0.029442\n",
      "(Iteration 7461 / 12100) loss: 0.040456\n",
      "(Iteration 7471 / 12100) loss: 0.030855\n",
      "(Iteration 7481 / 12100) loss: 0.032589\n",
      "(Iteration 7491 / 12100) loss: 0.034425\n",
      "(Iteration 7501 / 12100) loss: 0.030490\n",
      "(Epoch 8 / 5000) train acc: 0.942149; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 7511 / 12100) loss: 0.030789\n",
      "(Iteration 7521 / 12100) loss: 0.043023\n",
      "(Iteration 7531 / 12100) loss: 0.029290\n",
      "(Iteration 7541 / 12100) loss: 0.030854\n",
      "(Iteration 7551 / 12100) loss: 0.031231\n",
      "(Iteration 7561 / 12100) loss: 0.032731\n",
      "(Iteration 7571 / 12100) loss: 0.031586\n",
      "(Iteration 7581 / 12100) loss: 0.034339\n",
      "(Iteration 7591 / 12100) loss: 0.037390\n",
      "(Iteration 7601 / 12100) loss: 0.029328\n",
      "(Iteration 7611 / 12100) loss: 0.029118\n",
      "(Iteration 7621 / 12100) loss: 0.033642\n",
      "(Iteration 7631 / 12100) loss: 0.030939\n",
      "(Iteration 7641 / 12100) loss: 0.056812\n",
      "(Iteration 7651 / 12100) loss: 0.032469\n",
      "(Iteration 7661 / 12100) loss: 0.032748\n",
      "(Iteration 7671 / 12100) loss: 0.039390\n",
      "(Iteration 7681 / 12100) loss: 0.048777\n",
      "(Iteration 7691 / 12100) loss: 0.048246\n",
      "(Iteration 7701 / 12100) loss: 0.031218\n",
      "(Iteration 7711 / 12100) loss: 0.046425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 7721 / 12100) loss: 0.036575\n",
      "(Iteration 7731 / 12100) loss: 0.035039\n",
      "(Iteration 7741 / 12100) loss: 0.051712\n",
      "(Iteration 7751 / 12100) loss: 0.051466\n",
      "(Iteration 7761 / 12100) loss: 0.038048\n",
      "(Iteration 7771 / 12100) loss: 0.032121\n",
      "(Iteration 7781 / 12100) loss: 0.033759\n",
      "(Iteration 7791 / 12100) loss: 0.034612\n",
      "(Iteration 7801 / 12100) loss: 0.030434\n",
      "(Iteration 7811 / 12100) loss: 0.037044\n",
      "(Iteration 7821 / 12100) loss: 0.030333\n",
      "(Iteration 7831 / 12100) loss: 0.033688\n",
      "(Iteration 7841 / 12100) loss: 0.031639\n",
      "(Iteration 7851 / 12100) loss: 0.031911\n",
      "(Iteration 7861 / 12100) loss: 0.081792\n",
      "(Iteration 7871 / 12100) loss: 0.050829\n",
      "(Iteration 7881 / 12100) loss: 0.039753\n",
      "(Iteration 7891 / 12100) loss: 0.034685\n",
      "(Iteration 7901 / 12100) loss: 0.035790\n",
      "(Iteration 7911 / 12100) loss: 0.031555\n",
      "(Iteration 7921 / 12100) loss: 0.040675\n",
      "(Iteration 7931 / 12100) loss: 0.037826\n",
      "(Iteration 7941 / 12100) loss: 0.038032\n",
      "(Iteration 7951 / 12100) loss: 0.044962\n",
      "(Iteration 7961 / 12100) loss: 0.035277\n",
      "(Iteration 7971 / 12100) loss: 0.042198\n",
      "(Iteration 7981 / 12100) loss: 0.039188\n",
      "(Iteration 7991 / 12100) loss: 0.051911\n",
      "(Iteration 8001 / 12100) loss: 0.063034\n",
      "(Epoch 9 / 5000) train acc: 0.942149; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 8011 / 12100) loss: 0.058021\n",
      "(Iteration 8021 / 12100) loss: 0.041831\n",
      "(Iteration 8031 / 12100) loss: 0.037043\n",
      "(Iteration 8041 / 12100) loss: 0.032617\n",
      "(Iteration 8051 / 12100) loss: 0.036262\n",
      "(Iteration 8061 / 12100) loss: 0.031691\n",
      "(Iteration 8071 / 12100) loss: 0.031549\n",
      "(Iteration 8081 / 12100) loss: 0.032416\n",
      "(Iteration 8091 / 12100) loss: 0.030462\n",
      "(Iteration 8101 / 12100) loss: 0.059708\n",
      "(Iteration 8111 / 12100) loss: 0.032161\n",
      "(Iteration 8121 / 12100) loss: 0.041205\n",
      "(Iteration 8131 / 12100) loss: 0.029967\n",
      "(Iteration 8141 / 12100) loss: 0.030678\n",
      "(Iteration 8151 / 12100) loss: 0.035010\n",
      "(Iteration 8161 / 12100) loss: 0.030342\n",
      "(Iteration 8171 / 12100) loss: 0.029221\n",
      "(Iteration 8181 / 12100) loss: 0.035727\n",
      "(Iteration 8191 / 12100) loss: 0.033703\n",
      "(Iteration 8201 / 12100) loss: 0.035595\n",
      "(Iteration 8211 / 12100) loss: 0.029088\n",
      "(Iteration 8221 / 12100) loss: 0.029017\n",
      "(Iteration 8231 / 12100) loss: 0.058171\n",
      "(Iteration 8241 / 12100) loss: 0.038286\n",
      "(Iteration 8251 / 12100) loss: 0.028528\n",
      "(Iteration 8261 / 12100) loss: 0.038931\n",
      "(Iteration 8271 / 12100) loss: 0.031858\n",
      "(Iteration 8281 / 12100) loss: 0.027823\n",
      "(Iteration 8291 / 12100) loss: 0.030989\n",
      "(Iteration 8301 / 12100) loss: 0.029454\n",
      "(Iteration 8311 / 12100) loss: 0.032050\n",
      "(Iteration 8321 / 12100) loss: 0.033613\n",
      "(Iteration 8331 / 12100) loss: 0.050998\n",
      "(Iteration 8341 / 12100) loss: 0.041951\n",
      "(Iteration 8351 / 12100) loss: 0.030241\n",
      "(Iteration 8361 / 12100) loss: 0.035875\n",
      "(Iteration 8371 / 12100) loss: 0.050501\n",
      "(Iteration 8381 / 12100) loss: 0.034776\n",
      "(Iteration 8391 / 12100) loss: 0.035560\n",
      "(Iteration 8401 / 12100) loss: 0.029745\n",
      "(Iteration 8411 / 12100) loss: 0.028675\n",
      "(Iteration 8421 / 12100) loss: 0.040387\n",
      "(Iteration 8431 / 12100) loss: 0.030628\n",
      "(Iteration 8441 / 12100) loss: 0.038656\n",
      "(Iteration 8451 / 12100) loss: 0.037719\n",
      "(Iteration 8461 / 12100) loss: 0.037450\n",
      "(Iteration 8471 / 12100) loss: 0.028806\n",
      "(Iteration 8481 / 12100) loss: 0.032259\n",
      "(Iteration 8491 / 12100) loss: 0.070884\n",
      "(Iteration 8501 / 12100) loss: 0.029412\n",
      "(Epoch 9 / 5000) train acc: 0.954545; val_acc: 0.852459\n",
      "F1: 0.8656716417910448 \t Precision 0.8055555555555556 \t recall 0.9354838709677419\n",
      "(Iteration 8511 / 12100) loss: 0.081546\n",
      "(Iteration 8521 / 12100) loss: 0.037537\n",
      "(Iteration 8531 / 12100) loss: 0.121434\n",
      "(Iteration 8541 / 12100) loss: 0.035863\n",
      "(Iteration 8551 / 12100) loss: 0.050870\n",
      "(Iteration 8561 / 12100) loss: 0.032102\n",
      "(Iteration 8571 / 12100) loss: 0.031349\n",
      "(Iteration 8581 / 12100) loss: 0.041604\n",
      "(Iteration 8591 / 12100) loss: 0.030789\n",
      "(Iteration 8601 / 12100) loss: 0.036158\n",
      "(Iteration 8611 / 12100) loss: 0.059650\n",
      "(Iteration 8621 / 12100) loss: 0.034704\n",
      "(Iteration 8631 / 12100) loss: 0.050846\n",
      "(Iteration 8641 / 12100) loss: 0.036460\n",
      "(Iteration 8651 / 12100) loss: 0.039687\n",
      "(Iteration 8661 / 12100) loss: 0.033408\n",
      "(Iteration 8671 / 12100) loss: 0.036376\n",
      "(Iteration 8681 / 12100) loss: 0.031352\n",
      "(Iteration 8691 / 12100) loss: 0.034406\n",
      "(Iteration 8701 / 12100) loss: 0.058317\n",
      "(Iteration 8711 / 12100) loss: 0.031929\n",
      "(Iteration 8721 / 12100) loss: 0.030770\n",
      "(Iteration 8731 / 12100) loss: 0.053560\n",
      "(Iteration 8741 / 12100) loss: 0.033968\n",
      "(Iteration 8751 / 12100) loss: 0.044375\n",
      "(Iteration 8761 / 12100) loss: 0.059640\n",
      "(Iteration 8771 / 12100) loss: 0.039578\n",
      "(Iteration 8781 / 12100) loss: 0.057837\n",
      "(Iteration 8791 / 12100) loss: 0.042333\n",
      "(Iteration 8801 / 12100) loss: 0.078957\n",
      "(Iteration 8811 / 12100) loss: 0.035826\n",
      "(Iteration 8821 / 12100) loss: 0.052999\n",
      "(Iteration 8831 / 12100) loss: 0.046777\n",
      "(Iteration 8841 / 12100) loss: 0.039384\n",
      "(Iteration 8851 / 12100) loss: 0.032935\n",
      "(Iteration 8861 / 12100) loss: 0.033466\n",
      "(Iteration 8871 / 12100) loss: 0.033619\n",
      "(Iteration 8881 / 12100) loss: 0.045465\n",
      "(Iteration 8891 / 12100) loss: 0.031262\n",
      "(Iteration 8901 / 12100) loss: 0.031612\n",
      "(Iteration 8911 / 12100) loss: 0.038220\n",
      "(Iteration 8921 / 12100) loss: 0.032530\n",
      "(Iteration 8931 / 12100) loss: 0.031897\n",
      "(Iteration 8941 / 12100) loss: 0.033472\n",
      "(Iteration 8951 / 12100) loss: 0.029789\n",
      "(Iteration 8961 / 12100) loss: 0.045170\n",
      "(Iteration 8971 / 12100) loss: 0.031840\n",
      "(Iteration 8981 / 12100) loss: 0.031254\n",
      "(Iteration 8991 / 12100) loss: 0.035580\n",
      "(Iteration 9001 / 12100) loss: 0.029977\n",
      "(Epoch 10 / 5000) train acc: 0.962810; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 9011 / 12100) loss: 0.068307\n",
      "(Iteration 9021 / 12100) loss: 0.053126\n",
      "(Iteration 9031 / 12100) loss: 0.045389\n",
      "(Iteration 9041 / 12100) loss: 0.108076\n",
      "(Iteration 9051 / 12100) loss: 0.030222\n",
      "(Iteration 9061 / 12100) loss: 0.034737\n",
      "(Iteration 9071 / 12100) loss: 0.080604\n",
      "(Iteration 9081 / 12100) loss: 0.033490\n",
      "(Iteration 9091 / 12100) loss: 0.029486\n",
      "(Iteration 9101 / 12100) loss: 0.032776\n",
      "(Iteration 9111 / 12100) loss: 0.074179\n",
      "(Iteration 9121 / 12100) loss: 0.031274\n",
      "(Iteration 9131 / 12100) loss: 0.033039\n",
      "(Iteration 9141 / 12100) loss: 0.035201\n",
      "(Iteration 9151 / 12100) loss: 0.030070\n",
      "(Iteration 9161 / 12100) loss: 0.031719\n",
      "(Iteration 9171 / 12100) loss: 0.045667\n",
      "(Iteration 9181 / 12100) loss: 0.031162\n",
      "(Iteration 9191 / 12100) loss: 0.041933\n",
      "(Iteration 9201 / 12100) loss: 0.029225\n",
      "(Iteration 9211 / 12100) loss: 0.029790\n",
      "(Iteration 9221 / 12100) loss: 0.028865\n",
      "(Iteration 9231 / 12100) loss: 0.028935\n",
      "(Iteration 9241 / 12100) loss: 0.029376\n",
      "(Iteration 9251 / 12100) loss: 0.028102\n",
      "(Iteration 9261 / 12100) loss: 0.032903\n",
      "(Iteration 9271 / 12100) loss: 0.030228\n",
      "(Iteration 9281 / 12100) loss: 0.046095\n",
      "(Iteration 9291 / 12100) loss: 0.027971\n",
      "(Iteration 9301 / 12100) loss: 0.032482\n",
      "(Iteration 9311 / 12100) loss: 0.027823\n",
      "(Iteration 9321 / 12100) loss: 0.033717\n",
      "(Iteration 9331 / 12100) loss: 0.028029\n",
      "(Iteration 9341 / 12100) loss: 0.028524\n",
      "(Iteration 9351 / 12100) loss: 0.028528\n",
      "(Iteration 9361 / 12100) loss: 0.030239\n",
      "(Iteration 9371 / 12100) loss: 0.029915\n",
      "(Iteration 9381 / 12100) loss: 0.029396\n",
      "(Iteration 9391 / 12100) loss: 0.029781\n",
      "(Iteration 9401 / 12100) loss: 0.027707\n",
      "(Iteration 9411 / 12100) loss: 0.040912\n",
      "(Iteration 9421 / 12100) loss: 0.030678\n",
      "(Iteration 9431 / 12100) loss: 0.028345\n",
      "(Iteration 9441 / 12100) loss: 0.035978\n",
      "(Iteration 9451 / 12100) loss: 0.036094\n",
      "(Iteration 9461 / 12100) loss: 0.064212\n",
      "(Iteration 9471 / 12100) loss: 0.030385\n",
      "(Iteration 9481 / 12100) loss: 0.036309\n",
      "(Iteration 9491 / 12100) loss: 0.040370\n",
      "(Iteration 9501 / 12100) loss: 0.040356\n",
      "(Epoch 10 / 5000) train acc: 0.950413; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 9511 / 12100) loss: 0.033575\n",
      "(Iteration 9521 / 12100) loss: 0.037469\n",
      "(Iteration 9531 / 12100) loss: 0.065442\n",
      "(Iteration 9541 / 12100) loss: 0.069356\n",
      "(Iteration 9551 / 12100) loss: 0.038986\n",
      "(Iteration 9561 / 12100) loss: 0.060506\n",
      "(Iteration 9571 / 12100) loss: 0.031678\n",
      "(Iteration 9581 / 12100) loss: 0.032731\n",
      "(Iteration 9591 / 12100) loss: 0.076023\n",
      "(Iteration 9601 / 12100) loss: 0.037661\n",
      "(Iteration 9611 / 12100) loss: 0.034854\n",
      "(Iteration 9621 / 12100) loss: 0.035955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 9631 / 12100) loss: 0.036561\n",
      "(Iteration 9641 / 12100) loss: 0.034963\n",
      "(Iteration 9651 / 12100) loss: 0.099825\n",
      "(Iteration 9661 / 12100) loss: 0.039213\n",
      "(Iteration 9671 / 12100) loss: 0.056001\n",
      "(Iteration 9681 / 12100) loss: 0.032279\n",
      "(Iteration 9691 / 12100) loss: 0.030943\n",
      "(Iteration 9701 / 12100) loss: 0.063115\n",
      "(Iteration 9711 / 12100) loss: 0.033527\n",
      "(Iteration 9721 / 12100) loss: 0.030690\n",
      "(Iteration 9731 / 12100) loss: 0.060263\n",
      "(Iteration 9741 / 12100) loss: 0.071146\n",
      "(Iteration 9751 / 12100) loss: 0.031570\n",
      "(Iteration 9761 / 12100) loss: 0.031967\n",
      "(Iteration 9771 / 12100) loss: 0.058168\n",
      "(Iteration 9781 / 12100) loss: 0.038244\n",
      "(Iteration 9791 / 12100) loss: 0.033012\n",
      "(Iteration 9801 / 12100) loss: 0.049848\n",
      "(Iteration 9811 / 12100) loss: 0.036800\n",
      "(Iteration 9821 / 12100) loss: 0.031009\n",
      "(Iteration 9831 / 12100) loss: 0.033195\n",
      "(Iteration 9841 / 12100) loss: 0.032753\n",
      "(Iteration 9851 / 12100) loss: 0.091005\n",
      "(Iteration 9861 / 12100) loss: 0.051784\n",
      "(Iteration 9871 / 12100) loss: 0.052538\n",
      "(Iteration 9881 / 12100) loss: 0.048947\n",
      "(Iteration 9891 / 12100) loss: 0.058429\n",
      "(Iteration 9901 / 12100) loss: 0.053679\n",
      "(Iteration 9911 / 12100) loss: 0.045545\n",
      "(Iteration 9921 / 12100) loss: 0.032433\n",
      "(Iteration 9931 / 12100) loss: 0.032954\n",
      "(Iteration 9941 / 12100) loss: 0.034308\n",
      "(Iteration 9951 / 12100) loss: 0.036379\n",
      "(Iteration 9961 / 12100) loss: 0.037074\n",
      "(Iteration 9971 / 12100) loss: 0.057584\n",
      "(Iteration 9981 / 12100) loss: 0.038499\n",
      "(Iteration 9991 / 12100) loss: 0.032691\n",
      "(Iteration 10001 / 12100) loss: 0.031371\n",
      "(Epoch 11 / 5000) train acc: 0.942149; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 10011 / 12100) loss: 0.031003\n",
      "(Iteration 10021 / 12100) loss: 0.031226\n",
      "(Iteration 10031 / 12100) loss: 0.035508\n",
      "(Iteration 10041 / 12100) loss: 0.034128\n",
      "(Iteration 10051 / 12100) loss: 0.039074\n",
      "(Iteration 10061 / 12100) loss: 0.038999\n",
      "(Iteration 10071 / 12100) loss: 0.051085\n",
      "(Iteration 10081 / 12100) loss: 0.036818\n",
      "(Iteration 10091 / 12100) loss: 0.031619\n",
      "(Iteration 10101 / 12100) loss: 0.031894\n",
      "(Iteration 10111 / 12100) loss: 0.032917\n",
      "(Iteration 10121 / 12100) loss: 0.032061\n",
      "(Iteration 10131 / 12100) loss: 0.038962\n",
      "(Iteration 10141 / 12100) loss: 0.032833\n",
      "(Iteration 10151 / 12100) loss: 0.030548\n",
      "(Iteration 10161 / 12100) loss: 0.033062\n",
      "(Iteration 10171 / 12100) loss: 0.039744\n",
      "(Iteration 10181 / 12100) loss: 0.040550\n",
      "(Iteration 10191 / 12100) loss: 0.033313\n",
      "(Iteration 10201 / 12100) loss: 0.036288\n",
      "(Iteration 10211 / 12100) loss: 0.035181\n",
      "(Iteration 10221 / 12100) loss: 0.032807\n",
      "(Iteration 10231 / 12100) loss: 0.033862\n",
      "(Iteration 10241 / 12100) loss: 0.040305\n",
      "(Iteration 10251 / 12100) loss: 0.033603\n",
      "(Iteration 10261 / 12100) loss: 0.030711\n",
      "(Iteration 10271 / 12100) loss: 0.062733\n",
      "(Iteration 10281 / 12100) loss: 0.040706\n",
      "(Iteration 10291 / 12100) loss: 0.040337\n",
      "(Iteration 10301 / 12100) loss: 0.036141\n",
      "(Iteration 10311 / 12100) loss: 0.060631\n",
      "(Iteration 10321 / 12100) loss: 0.094056\n",
      "(Iteration 10331 / 12100) loss: 0.138976\n",
      "(Iteration 10341 / 12100) loss: 0.031842\n",
      "(Iteration 10351 / 12100) loss: 0.035169\n",
      "(Iteration 10361 / 12100) loss: 0.032458\n",
      "(Iteration 10371 / 12100) loss: 0.035339\n",
      "(Iteration 10381 / 12100) loss: 0.033821\n",
      "(Iteration 10391 / 12100) loss: 0.037160\n",
      "(Iteration 10401 / 12100) loss: 0.062595\n",
      "(Iteration 10411 / 12100) loss: 0.045627\n",
      "(Iteration 10421 / 12100) loss: 0.033964\n",
      "(Iteration 10431 / 12100) loss: 0.032264\n",
      "(Iteration 10441 / 12100) loss: 0.037648\n",
      "(Iteration 10451 / 12100) loss: 0.032887\n",
      "(Iteration 10461 / 12100) loss: 0.032254\n",
      "(Iteration 10471 / 12100) loss: 0.085396\n",
      "(Iteration 10481 / 12100) loss: 0.037904\n",
      "(Iteration 10491 / 12100) loss: 0.039215\n",
      "(Iteration 10501 / 12100) loss: 0.031838\n",
      "(Epoch 11 / 5000) train acc: 0.950413; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 10511 / 12100) loss: 0.034315\n",
      "(Iteration 10521 / 12100) loss: 0.040180\n",
      "(Iteration 10531 / 12100) loss: 0.055734\n",
      "(Iteration 10541 / 12100) loss: 0.045993\n",
      "(Iteration 10551 / 12100) loss: 0.047041\n",
      "(Iteration 10561 / 12100) loss: 0.036003\n",
      "(Iteration 10571 / 12100) loss: 0.036783\n",
      "(Iteration 10581 / 12100) loss: 0.040395\n",
      "(Iteration 10591 / 12100) loss: 0.031139\n",
      "(Iteration 10601 / 12100) loss: 0.034182\n",
      "(Iteration 10611 / 12100) loss: 0.035483\n",
      "(Iteration 10621 / 12100) loss: 0.031340\n",
      "(Iteration 10631 / 12100) loss: 0.034690\n",
      "(Iteration 10641 / 12100) loss: 0.032981\n",
      "(Iteration 10651 / 12100) loss: 0.031821\n",
      "(Iteration 10661 / 12100) loss: 0.031089\n",
      "(Iteration 10671 / 12100) loss: 0.031236\n",
      "(Iteration 10681 / 12100) loss: 0.031212\n",
      "(Iteration 10691 / 12100) loss: 0.099317\n",
      "(Iteration 10701 / 12100) loss: 0.031786\n",
      "(Iteration 10711 / 12100) loss: 0.031292\n",
      "(Iteration 10721 / 12100) loss: 0.032874\n",
      "(Iteration 10731 / 12100) loss: 0.039571\n",
      "(Iteration 10741 / 12100) loss: 0.031260\n",
      "(Iteration 10751 / 12100) loss: 0.031954\n",
      "(Iteration 10761 / 12100) loss: 0.041993\n",
      "(Iteration 10771 / 12100) loss: 0.032574\n",
      "(Iteration 10781 / 12100) loss: 0.033890\n",
      "(Iteration 10791 / 12100) loss: 0.033015\n",
      "(Iteration 10801 / 12100) loss: 0.031550\n",
      "(Iteration 10811 / 12100) loss: 0.029454\n",
      "(Iteration 10821 / 12100) loss: 0.031545\n",
      "(Iteration 10831 / 12100) loss: 0.030505\n",
      "(Iteration 10841 / 12100) loss: 0.028949\n",
      "(Iteration 10851 / 12100) loss: 0.028395\n",
      "(Iteration 10861 / 12100) loss: 0.038119\n",
      "(Iteration 10871 / 12100) loss: 0.043473\n",
      "(Iteration 10881 / 12100) loss: 0.039133\n",
      "(Iteration 10891 / 12100) loss: 0.036245\n",
      "(Iteration 10901 / 12100) loss: 0.029485\n",
      "(Iteration 10911 / 12100) loss: 0.028529\n",
      "(Iteration 10921 / 12100) loss: 0.029018\n",
      "(Iteration 10931 / 12100) loss: 0.028259\n",
      "(Iteration 10941 / 12100) loss: 0.030012\n",
      "(Iteration 10951 / 12100) loss: 0.028606\n",
      "(Iteration 10961 / 12100) loss: 0.028205\n",
      "(Iteration 10971 / 12100) loss: 0.031898\n",
      "(Iteration 10981 / 12100) loss: 0.029830\n",
      "(Iteration 10991 / 12100) loss: 0.030514\n",
      "(Iteration 11001 / 12100) loss: 0.045672\n",
      "(Epoch 12 / 5000) train acc: 0.958678; val_acc: 0.885246\n",
      "F1: 0.8923076923076922 \t Precision 0.8529411764705882 \t recall 0.9354838709677419\n",
      "(Iteration 11011 / 12100) loss: 0.029004\n",
      "(Iteration 11021 / 12100) loss: 0.027326\n",
      "(Iteration 11031 / 12100) loss: 0.030721\n",
      "(Iteration 11041 / 12100) loss: 0.030988\n",
      "(Iteration 11051 / 12100) loss: 0.027969\n",
      "(Iteration 11061 / 12100) loss: 0.028421\n",
      "(Iteration 11071 / 12100) loss: 0.032983\n",
      "(Iteration 11081 / 12100) loss: 0.029305\n",
      "(Iteration 11091 / 12100) loss: 0.027081\n",
      "(Iteration 11101 / 12100) loss: 0.068258\n",
      "(Iteration 11111 / 12100) loss: 0.030400\n",
      "(Iteration 11121 / 12100) loss: 0.030899\n",
      "(Iteration 11131 / 12100) loss: 0.034400\n",
      "(Iteration 11141 / 12100) loss: 0.031782\n",
      "(Iteration 11151 / 12100) loss: 0.028159\n",
      "(Iteration 11161 / 12100) loss: 0.064823\n",
      "(Iteration 11171 / 12100) loss: 0.030527\n",
      "(Iteration 11181 / 12100) loss: 0.029503\n",
      "(Iteration 11191 / 12100) loss: 0.035827\n",
      "(Iteration 11201 / 12100) loss: 0.030837\n",
      "(Iteration 11211 / 12100) loss: 0.034784\n"
     ]
    }
   ],
   "source": [
    "model = FullyConnectedNet([300, 200], input_dim=13, num_classes=2, dropout=0.5, reg=0.001)\n",
    "\n",
    "\n",
    "trainer = trainer.Trainer(model, data, num_epochs=5000)\n",
    "trainer.train()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trainer.get_losshistory(), 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(trainer.get_train_acc_history(), '-o')\n",
    "plt.plot(trainer.get_val_acc_history(), '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
